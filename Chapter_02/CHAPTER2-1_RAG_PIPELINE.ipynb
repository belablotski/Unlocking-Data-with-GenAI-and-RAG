{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d124d22-de73-436b-86cd-9b162b469be8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (25.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Skipping langchain-core as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping langchain-openai as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping langchain-experimental as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping beautifulsoup4 as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping langchain-community as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping langchain as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping chromadb as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain-core==0.3.6\n",
      "  Downloading langchain_core-0.3.6-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain-core==0.3.6)\n",
      "  Downloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core==0.3.6)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.125 (from langchain-core==0.3.6)\n",
      "  Downloading langsmith-0.1.147-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core==0.3.6)\n",
      "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting pydantic<3.0.0,>=2.5.2 (from langchain-core==0.3.6)\n",
      "  Downloading pydantic-2.11.3-py3-none-any.whl.metadata (65 kB)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain-core==0.3.6)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting typing-extensions>=4.7 (from langchain-core==0.3.6)\n",
      "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core==0.3.6)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.125->langchain-core==0.3.6)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.125->langchain-core==0.3.6)\n",
      "  Downloading orjson-3.10.16-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting requests<3,>=2 (from langsmith<0.2.0,>=0.1.125->langchain-core==0.3.6)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.125->langchain-core==0.3.6)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.5.2->langchain-core==0.3.6)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.1 (from pydantic<3.0.0,>=2.5.2->langchain-core==0.3.6)\n",
      "  Downloading pydantic_core-2.33.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3.0.0,>=2.5.2->langchain-core==0.3.6)\n",
      "  Downloading typing_inspection-0.4.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core==0.3.6)\n",
      "  Downloading anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting certifi (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core==0.3.6)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core==0.3.6)\n",
      "  Downloading httpcore-1.0.8-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core==0.3.6)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core==0.3.6)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core==0.3.6)\n",
      "  Downloading charset_normalizer-3.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core==0.3.6)\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-core==0.3.6)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Downloading langchain_core-0.3.6-py3-none-any.whl (399 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading langsmith-0.1.147-py3-none-any.whl (311 kB)\n",
      "Downloading packaging-24.2-py3-none-any.whl (65 kB)\n",
      "Downloading pydantic-2.11.3-py3-none-any.whl (443 kB)\n",
      "Downloading pydantic_core-2.33.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (767 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m767.5/767.5 kB\u001b[0m \u001b[31m36.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.8-py3-none-any.whl (78 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading orjson-3.10.16-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (133 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading typing_inspection-0.4.0-py3-none-any.whl (14 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Downloading charset_normalizer-3.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (145 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Downloading anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: urllib3, typing-extensions, tenacity, sniffio, PyYAML, packaging, orjson, jsonpointer, idna, h11, charset-normalizer, certifi, annotated-types, typing-inspection, requests, pydantic-core, jsonpatch, httpcore, anyio, requests-toolbelt, pydantic, httpx, langsmith, langchain-core\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 25.0\n",
      "    Uninstalling packaging-25.0:\n",
      "      Successfully uninstalled packaging-25.0\n",
      "Successfully installed PyYAML-6.0.2 annotated-types-0.7.0 anyio-4.9.0 certifi-2025.1.31 charset-normalizer-3.4.1 h11-0.14.0 httpcore-1.0.8 httpx-0.28.1 idna-3.10 jsonpatch-1.33 jsonpointer-3.0.0 langchain-core-0.3.6 langsmith-0.1.147 orjson-3.10.16 packaging-24.2 pydantic-2.11.3 pydantic-core-2.33.1 requests-2.32.3 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-8.5.0 typing-extensions-4.13.2 typing-inspection-0.4.0 urllib3-2.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain-openai==0.2.1\n",
      "  Downloading langchain_openai-0.2.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.3 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-openai==0.2.1) (0.3.6)\n",
      "Collecting openai<2.0.0,>=1.40.0 (from langchain-openai==0.2.1)\n",
      "  Downloading openai-1.75.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting tiktoken<1,>=0.7 (from langchain-openai==0.2.1)\n",
      "  Downloading tiktoken-0.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3->langchain-openai==0.2.1) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3->langchain-openai==0.2.1) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3->langchain-openai==0.2.1) (0.1.147)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3->langchain-openai==0.2.1) (24.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3->langchain-openai==0.2.1) (2.11.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3->langchain-openai==0.2.1) (8.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-core<0.4,>=0.3->langchain-openai==0.2.1) (4.13.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.1) (4.9.0)\n",
      "Collecting distro<2,>=1.7.0 (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.1)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.1) (0.28.1)\n",
      "Collecting jiter<1,>=0.4.0 (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.1)\n",
      "  Downloading jiter-0.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: sniffio in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.1) (1.3.1)\n",
      "Collecting tqdm>4 (from openai<2.0.0,>=1.40.0->langchain-openai==0.2.1)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken<1,>=0.7->langchain-openai==0.2.1)\n",
      "  Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests>=2.26.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from tiktoken<1,>=0.7->langchain-openai==0.2.1) (2.32.3)\n",
      "Requirement already satisfied: idna>=2.8 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai==0.2.1) (3.10)\n",
      "Requirement already satisfied: certifi in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai==0.2.1) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai==0.2.1) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai==0.2.1) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3->langchain-openai==0.2.1) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-openai==0.2.1) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-openai==0.2.1) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain-openai==0.2.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain-openai==0.2.1) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain-openai==0.2.1) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.2.1) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai==0.2.1) (2.4.0)\n",
      "Downloading langchain_openai-0.2.1-py3-none-any.whl (49 kB)\n",
      "Downloading openai-1.75.0-py3-none-any.whl (646 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m647.0/647.0 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tiktoken-0.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m42.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.9.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (351 kB)\n",
      "Downloading regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (796 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m796.9/796.9 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, regex, jiter, distro, tiktoken, openai, langchain-openai\n",
      "Successfully installed distro-1.9.0 jiter-0.9.0 langchain-openai-0.2.1 openai-1.75.0 regex-2024.11.6 tiktoken-0.9.0 tqdm-4.67.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain-experimental==0.3.2\n",
      "  Downloading langchain_experimental-0.3.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting langchain-community<0.4.0,>=0.3.0 (from langchain-experimental==0.3.2)\n",
      "  Downloading langchain_community-0.3.21-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-experimental==0.3.2) (0.3.6)\n",
      "Collecting langchain-core<0.4.0,>=0.3.6 (from langchain-experimental==0.3.2)\n",
      "  Downloading langchain_core-0.3.55-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain<1.0.0,>=0.3.23 (from langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2)\n",
      "  Downloading langchain-0.3.23-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2)\n",
      "  Downloading sqlalchemy-2.0.40-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (6.0.2)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2)\n",
      "  Downloading aiohttp-3.11.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (8.5.0)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2)\n",
      "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (0.1.147)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2)\n",
      "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting numpy<3,>=1.26.2 (from langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2)\n",
      "  Downloading numpy-2.2.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-experimental==0.3.2) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-experimental==0.3.2) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-experimental==0.3.2) (4.13.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-experimental==0.3.2) (2.11.3)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2)\n",
      "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2)\n",
      "  Downloading frozenlist-1.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2)\n",
      "  Downloading multidict-6.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2)\n",
      "  Downloading propcache-0.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2)\n",
      "  Downloading yarl-1.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (72 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2)\n",
      "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain-experimental==0.3.2) (3.0.0)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain<1.0.0,>=0.3.23->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2)\n",
      "  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.6->langchain-experimental==0.3.2) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.6->langchain-experimental==0.3.2) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.6->langchain-experimental==0.3.2) (0.4.0)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2)\n",
      "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (2025.1.31)\n",
      "Collecting greenlet>=1 (from SQLAlchemy<3,>=1.4->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2)\n",
      "  Downloading greenlet-3.2.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: anyio in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (0.14.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community<0.4.0,>=0.3.0->langchain-experimental==0.3.2) (1.3.1)\n",
      "Downloading langchain_experimental-0.3.2-py3-none-any.whl (208 kB)\n",
      "Downloading langchain_community-0.3.21-py3-none-any.whl (2.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_core-0.3.55-py3-none-any.whl (434 kB)\n",
      "Downloading aiohttp-3.11.18-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading langchain-0.3.23-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-2.2.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/16.1 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
      "Downloading sqlalchemy-2.0.40-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.6.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (316 kB)\n",
      "Downloading greenlet-3.2.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (603 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m603.8/603.8 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\n",
      "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.4.3-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
      "Downloading propcache-0.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (245 kB)\n",
      "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.20.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (349 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: python-dotenv, propcache, numpy, mypy-extensions, multidict, marshmallow, httpx-sse, greenlet, frozenlist, attrs, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain-core, langchain-text-splitters, langchain, langchain-community, langchain-experimental\n",
      "  Attempting uninstall: langchain-core\n",
      "    Found existing installation: langchain-core 0.3.6\n",
      "    Uninstalling langchain-core-0.3.6:\n",
      "      Successfully uninstalled langchain-core-0.3.6\n",
      "Successfully installed SQLAlchemy-2.0.40 aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 attrs-25.3.0 dataclasses-json-0.6.7 frozenlist-1.6.0 greenlet-3.2.0 httpx-sse-0.4.0 langchain-0.3.23 langchain-community-0.3.21 langchain-core-0.3.55 langchain-experimental-0.3.2 langchain-text-splitters-0.3.8 marshmallow-3.26.1 multidict-6.4.3 mypy-extensions-1.0.0 numpy-2.2.5 propcache-0.3.1 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0 yarl-1.20.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain-community==0.3.1\n",
      "  Downloading langchain_community-0.3.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-community==0.3.1) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-community==0.3.1) (2.0.40)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-community==0.3.1) (3.11.18)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-community==0.3.1) (0.6.7)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.1 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-community==0.3.1) (0.3.23)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-community==0.3.1) (0.3.55)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-community==0.3.1) (0.1.147)\n",
      "Collecting numpy<2.0.0,>=1.26.0 (from langchain-community==0.3.1)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-community==0.3.1) (2.9.1)\n",
      "Requirement already satisfied: requests<3,>=2 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-community==0.3.1) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-community==0.3.1) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.1) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.1) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.1) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.1) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.1) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.1) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.3.1) (1.20.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.1) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.1) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.1->langchain-community==0.3.1) (0.3.8)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain<0.4.0,>=0.3.1->langchain-community==0.3.1) (2.11.3)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community==0.3.1) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community==0.3.1) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain-community==0.3.1) (4.13.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community==0.3.1) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community==0.3.1) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community==0.3.1) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.1) (1.1.0)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community==0.3.1) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community==0.3.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community==0.3.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community==0.3.1) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain-community==0.3.1) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.3.1) (3.2.0)\n",
      "Requirement already satisfied: anyio in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community==0.3.1) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community==0.3.1) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community==0.3.1) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain-community==0.3.1) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain-community==0.3.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.1->langchain-community==0.3.1) (2.33.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.3.1) (1.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community==0.3.1) (1.3.1)\n",
      "Downloading langchain_community-0.3.1-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m43.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.26.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: numpy, langchain-community\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.2.5\n",
      "    Uninstalling numpy-2.2.5:\n",
      "      Successfully uninstalled numpy-2.2.5\n",
      "  Attempting uninstall: langchain-community\n",
      "    Found existing installation: langchain-community 0.3.21\n",
      "    Uninstalling langchain-community-0.3.21:\n",
      "      Successfully uninstalled langchain-community-0.3.21\n",
      "Successfully installed langchain-community-0.3.1 numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting langchain==0.3.1\n",
      "  Downloading langchain-0.3.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain==0.3.1) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain==0.3.1) (2.0.40)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain==0.3.1) (3.11.18)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.6 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain==0.3.1) (0.3.55)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain==0.3.1) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain==0.3.1) (0.1.147)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.26.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain==0.3.1) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain==0.3.1) (2.11.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain==0.3.1) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain==0.3.1) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain==0.3.1) (1.20.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain==0.3.1) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain==0.3.1) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langchain-core<0.4.0,>=0.3.6->langchain==0.3.1) (4.13.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.1) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.1) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from langsmith<0.2.0,>=0.1.17->langchain==0.3.1) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.1) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain==0.3.1) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.3.1) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.3.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.3.1) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from requests<3,>=2->langchain==0.3.1) (2025.1.31)\n",
      "Requirement already satisfied: greenlet>=1 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from SQLAlchemy<3,>=1.4->langchain==0.3.1) (3.2.0)\n",
      "Requirement already satisfied: anyio in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.1) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.1) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.1) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.6->langchain==0.3.1) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain==0.3.1) (1.3.1)\n",
      "Downloading langchain-0.3.1-py3-none-any.whl (1.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: langchain\n",
      "  Attempting uninstall: langchain\n",
      "    Found existing installation: langchain 0.3.23\n",
      "    Uninstalling langchain-0.3.23:\n",
      "      Successfully uninstalled langchain-0.3.23\n",
      "Successfully installed langchain-0.3.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting chromadb==0.5.11\n",
      "  Downloading chromadb-0.5.11-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting build>=1.0.3 (from chromadb==0.5.11)\n",
      "  Downloading build-1.2.2.post1-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: pydantic>=1.9 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from chromadb==0.5.11) (2.11.3)\n",
      "Collecting chroma-hnswlib==0.7.6 (from chromadb==0.5.11)\n",
      "  Downloading chroma_hnswlib-0.7.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (252 bytes)\n",
      "Collecting fastapi>=0.95.2 (from chromadb==0.5.11)\n",
      "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting uvicorn>=0.18.3 (from uvicorn[standard]>=0.18.3->chromadb==0.5.11)\n",
      "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy>=1.22.5 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from chromadb==0.5.11) (1.26.4)\n",
      "Collecting posthog>=2.4.0 (from chromadb==0.5.11)\n",
      "  Downloading posthog-3.25.0-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from chromadb==0.5.11) (4.13.2)\n",
      "Collecting onnxruntime>=1.14.1 (from chromadb==0.5.11)\n",
      "  Downloading onnxruntime-1.21.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.7 kB)\n",
      "Collecting opentelemetry-api>=1.2.0 (from chromadb==0.5.11)\n",
      "  Downloading opentelemetry_api-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb==0.5.11)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb==0.5.11)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb==0.5.11)\n",
      "  Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting tokenizers>=0.13.2 (from chromadb==0.5.11)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting pypika>=0.48.9 (from chromadb==0.5.11)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from chromadb==0.5.11) (4.67.1)\n",
      "Collecting overrides>=7.3.1 (from chromadb==0.5.11)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting importlib-resources (from chromadb==0.5.11)\n",
      "  Downloading importlib_resources-6.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting grpcio>=1.58.0 (from chromadb==0.5.11)\n",
      "  Downloading grpcio-1.71.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb==0.5.11)\n",
      "  Downloading bcrypt-4.3.0-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Collecting typer>=0.9.0 (from chromadb==0.5.11)\n",
      "  Downloading typer-0.15.2-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb==0.5.11)\n",
      "  Downloading kubernetes-32.0.1-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Requirement already satisfied: tenacity>=8.2.3 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from chromadb==0.5.11) (8.5.0)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from chromadb==0.5.11) (6.0.2)\n",
      "Collecting mmh3>=4.0.1 (from chromadb==0.5.11)\n",
      "  Downloading mmh3-5.1.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: orjson>=3.9.12 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from chromadb==0.5.11) (3.10.16)\n",
      "Requirement already satisfied: httpx>=0.27.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from chromadb==0.5.11) (0.28.1)\n",
      "Collecting rich>=10.11.0 (from chromadb==0.5.11)\n",
      "  Downloading rich-14.0.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: packaging>=19.1 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from build>=1.0.3->chromadb==0.5.11) (24.2)\n",
      "Collecting pyproject_hooks (from build>=1.0.3->chromadb==0.5.11)\n",
      "  Downloading pyproject_hooks-1.2.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting starlette<0.47.0,>=0.40.0 (from fastapi>=0.95.2->chromadb==0.5.11)\n",
      "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: anyio in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb==0.5.11) (4.9.0)\n",
      "Requirement already satisfied: certifi in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb==0.5.11) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb==0.5.11) (1.0.8)\n",
      "Requirement already satisfied: idna in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from httpx>=0.27.0->chromadb==0.5.11) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb==0.5.11) (0.14.0)\n",
      "Requirement already satisfied: six>=1.9.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.5.11) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.5.11) (2.9.0.post0)\n",
      "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb==0.5.11)\n",
      "  Downloading google_auth-2.39.0-py2.py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb==0.5.11)\n",
      "  Downloading websocket_client-1.8.0-py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: requests in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.5.11) (2.32.3)\n",
      "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb==0.5.11)\n",
      "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl.metadata (11 kB)\n",
      "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb==0.5.11)\n",
      "  Downloading oauthlib-3.2.2-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from kubernetes>=28.1.0->chromadb==0.5.11) (2.4.0)\n",
      "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb==0.5.11)\n",
      "  Downloading durationpy-0.9-py3-none-any.whl.metadata (338 bytes)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb==0.5.11)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb==0.5.11)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb==0.5.11)\n",
      "  Downloading protobuf-6.30.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
      "Collecting sympy (from onnxruntime>=1.14.1->chromadb==0.5.11)\n",
      "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb==0.5.11)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting importlib-metadata<8.7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb==0.5.11)\n",
      "  Downloading importlib_metadata-8.6.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.11)\n",
      "  Downloading googleapis_common_protos-1.70.0-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.11)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting opentelemetry-proto==1.32.1 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb==0.5.11)\n",
      "  Downloading opentelemetry_proto-1.32.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting protobuf (from onnxruntime>=1.14.1->chromadb==0.5.11)\n",
      "  Downloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
      "Collecting opentelemetry-instrumentation-asgi==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.11)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting opentelemetry-instrumentation==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.11)\n",
      "  Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.11)\n",
      "  Downloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting opentelemetry-util-http==0.53b1 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.11)\n",
      "  Downloading opentelemetry_util_http-0.53b1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.11)\n",
      "  Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.4 kB)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.53b1->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb==0.5.11)\n",
      "  Downloading asgiref-3.8.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb==0.5.11)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb==0.5.11)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: distro>=1.5.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from posthog>=2.4.0->chromadb==0.5.11) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from pydantic>=1.9->chromadb==0.5.11) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from pydantic>=1.9->chromadb==0.5.11) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from pydantic>=1.9->chromadb==0.5.11) (0.4.0)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb==0.5.11)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from rich>=10.11.0->chromadb==0.5.11) (2.19.1)\n",
      "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb==0.5.11)\n",
      "  Downloading huggingface_hub-0.30.2-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting click>=8.0.0 (from typer>=0.9.0->chromadb==0.5.11)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb==0.5.11)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.18.3->chromadb==0.5.11)\n",
      "  Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from uvicorn[standard]>=0.18.3->chromadb==0.5.11) (1.1.0)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb==0.5.11)\n",
      "  Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb==0.5.11)\n",
      "  Downloading watchfiles-1.0.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
      "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb==0.5.11)\n",
      "  Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.11)\n",
      "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.11)\n",
      "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.11)\n",
      "  Downloading rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.5.11)\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb==0.5.11)\n",
      "  Downloading fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb==0.5.11)\n",
      "  Downloading zipp-3.21.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb==0.5.11)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from requests->kubernetes>=28.1.0->chromadb==0.5.11) (3.4.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (from anyio->httpx>=0.27.0->chromadb==0.5.11) (1.3.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb==0.5.11)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb==0.5.11)\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting pyasn1<0.7.0,>=0.6.1 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb==0.5.11)\n",
      "  Downloading pyasn1-0.6.1-py3-none-any.whl.metadata (8.4 kB)\n",
      "Downloading chromadb-0.5.11-py3-none-any.whl (603 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m604.0/604.0 kB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading chroma_hnswlib-0.7.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading bcrypt-4.3.0-cp39-abi3-manylinux_2_28_x86_64.whl (284 kB)\n",
      "Downloading build-1.2.2.post1-py3-none-any.whl (22 kB)\n",
      "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
      "Downloading grpcio-1.71.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kubernetes-32.0.1-py2.py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading mmh3-5.1.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (101 kB)\n",
      "Downloading onnxruntime-1.21.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (16.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m56.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n",
      "\u001b[?25hDownloading opentelemetry_api-1.32.1-py3-none-any.whl (65 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_grpc-1.32.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.32.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.32.1-py3-none-any.whl (55 kB)\n",
      "Downloading opentelemetry_instrumentation_fastapi-0.53b1-py3-none-any.whl (12 kB)\n",
      "Downloading opentelemetry_instrumentation-0.53b1-py3-none-any.whl (30 kB)\n",
      "Downloading opentelemetry_instrumentation_asgi-0.53b1-py3-none-any.whl (16 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.53b1-py3-none-any.whl (188 kB)\n",
      "Downloading opentelemetry_util_http-0.53b1-py3-none-any.whl (7.3 kB)\n",
      "Downloading opentelemetry_sdk-1.32.1-py3-none-any.whl (118 kB)\n",
      "Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Downloading posthog-3.25.0-py2.py3-none-any.whl (89 kB)\n",
      "Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.15.2-py3-none-any.whl (45 kB)\n",
      "Downloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
      "Downloading importlib_resources-6.5.2-py3-none-any.whl (37 kB)\n",
      "Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading durationpy-0.9-py3-none-any.whl (3.5 kB)\n",
      "Downloading google_auth-2.39.0-py2.py3-none-any.whl (212 kB)\n",
      "Downloading googleapis_common_protos-1.70.0-py3-none-any.whl (294 kB)\n",
      "Downloading httptools-0.6.4-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (510 kB)\n",
      "Downloading huggingface_hub-0.30.2-py3-none-any.whl (481 kB)\n",
      "Downloading importlib_metadata-8.6.1-py3-none-any.whl (26 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Downloading protobuf-5.29.4-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
      "Downloading uvloop-0.21.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading watchfiles-1.0.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
      "Downloading websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
      "Downloading websockets-15.0.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (182 kB)\n",
      "Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading pyproject_hooks-1.2.0-py3-none-any.whl (10 kB)\n",
      "Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
      "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
      "Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
      "Downloading fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
      "Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
      "Downloading wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (89 kB)\n",
      "Downloading zipp-3.21.0-py3-none-any.whl (9.6 kB)\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pypika: filename=pypika-0.48.9-py2.py3-none-any.whl size=53801 sha256=fe81ea2d2df83a1bf425658c234aff64a119c462c4ed43bfa2d95d70f8491e0f\n",
      "  Stored in directory: /home/codespace/.cache/pip/wheels/d5/3d/69/8d68d249cd3de2584f226e27fd431d6344f7d70fd856ebd01b\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, mpmath, monotonic, flatbuffers, durationpy, zipp, wrapt, websockets, websocket-client, uvloop, sympy, shellingham, pyproject_hooks, pyasn1, protobuf, overrides, opentelemetry-util-http, oauthlib, mmh3, mdurl, importlib-resources, humanfriendly, httptools, grpcio, fsspec, filelock, click, chroma-hnswlib, cachetools, bcrypt, backoff, asgiref, watchfiles, uvicorn, starlette, rsa, requests-oauthlib, pyasn1-modules, posthog, opentelemetry-proto, markdown-it-py, importlib-metadata, huggingface-hub, googleapis-common-protos, deprecated, coloredlogs, build, tokenizers, rich, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, google-auth, fastapi, typer, opentelemetry-semantic-conventions, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
      "Successfully installed asgiref-3.8.1 backoff-2.2.1 bcrypt-4.3.0 build-1.2.2.post1 cachetools-5.5.2 chroma-hnswlib-0.7.6 chromadb-0.5.11 click-8.1.8 coloredlogs-15.0.1 deprecated-1.2.18 durationpy-0.9 fastapi-0.115.12 filelock-3.18.0 flatbuffers-25.2.10 fsspec-2025.3.2 google-auth-2.39.0 googleapis-common-protos-1.70.0 grpcio-1.71.0 httptools-0.6.4 huggingface-hub-0.30.2 humanfriendly-10.0 importlib-metadata-8.6.1 importlib-resources-6.5.2 kubernetes-32.0.1 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-5.1.0 monotonic-1.6 mpmath-1.3.0 oauthlib-3.2.2 onnxruntime-1.21.1 opentelemetry-api-1.32.1 opentelemetry-exporter-otlp-proto-common-1.32.1 opentelemetry-exporter-otlp-proto-grpc-1.32.1 opentelemetry-instrumentation-0.53b1 opentelemetry-instrumentation-asgi-0.53b1 opentelemetry-instrumentation-fastapi-0.53b1 opentelemetry-proto-1.32.1 opentelemetry-sdk-1.32.1 opentelemetry-semantic-conventions-0.53b1 opentelemetry-util-http-0.53b1 overrides-7.7.0 posthog-3.25.0 protobuf-5.29.4 pyasn1-0.6.1 pyasn1-modules-0.4.2 pypika-0.48.9 pyproject_hooks-1.2.0 requests-oauthlib-2.0.0 rich-14.0.0 rsa-4.9.1 shellingham-1.5.4 starlette-0.46.2 sympy-1.13.3 tokenizers-0.21.1 typer-0.15.2 uvicorn-0.34.2 uvloop-0.21.0 watchfiles-1.0.5 websocket-client-1.8.0 websockets-15.0.1 wrapt-1.17.2 zipp-3.21.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Collecting beautifulsoup4==4.12.3\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4==4.12.3)\n",
      "  Downloading soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Downloading soupsieve-2.7-py3-none-any.whl (36 kB)\n",
      "Installing collected packages: soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.12.3 soupsieve-2.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "\n",
    "# Uninstall conflicting packages\n",
    "%pip uninstall -y langchain-core langchain-openai langchain-experimental beautifulsoup4 langchain-community langchain chromadb beautifulsoup4\n",
    "\n",
    "# Install compatible versions of langchain-core and langchain-openai\n",
    "%pip install langchain-core==0.3.6\n",
    "%pip install langchain-openai==0.2.1\n",
    "%pip install langchain-experimental==0.3.2\n",
    "%pip install langchain-community==0.3.1\n",
    "%pip install langchain==0.3.1\n",
    "\n",
    "# Install remaining packages\n",
    "%pip install chromadb==0.5.11\n",
    "%pip install beautifulsoup4==4.12.3\n",
    "\n",
    "# Restart the kernel after installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "444bfbe3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pysqlite3-binary in /workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages (0.5.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pysqlite3-binary --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7ab2808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these three lines swap the stdlib sqlite3 lib with the pysqlite3 package\n",
    "__import__('pysqlite3')\n",
    "import sys, os\n",
    "sys.modules['sqlite3'] = sys.modules.pop('pysqlite3')\n",
    "\n",
    "# DATABASES = {\n",
    "#     'default': {\n",
    "#         'ENGINE': 'django.db.backends.sqlite3',\n",
    "#         'NAME': os.path.join(BASE_DIR, 'db.sqlite3'),\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0cd4b7a9-f8e8-4e23-9366-bdb6da2e360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New OS parameter to avoid warnings.  \n",
    "# This will not have a material impact on your code, but prevents warnings from appearing related to new LangChain features.\n",
    "import os\n",
    "os.environ['USER_AGENT'] = 'RAGUserAgent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f884314f-870c-4bfb-b6c1-a5b4801ec172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "import bs4\n",
    "import openai\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain import hub\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "import chromadb\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "721241b4-32ab-476a-a5ac-9feab48459e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI Setup\n",
    "\n",
    "import os\n",
    "\n",
    "# The key is in .env file\n",
    "# os.environ['OPENAI_API_KEY'] = ''\n",
    "\n",
    "openai.api_key = os.environ['OPENAI_API_KEY']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3ad428a-3eb6-40ec-a1a5-62565ead1e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### INDEXING ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98ccda2c-0f4c-41c5-804d-2227cdf35aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Documents\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://kbourne.github.io/chapter1.html\",), \n",
    "    bs_kwargs=dict(\n",
    "        parse_only=bs4.SoupStrainer(\n",
    "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
    "        )\n",
    "    ),\n",
    ")\n",
    "docs = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9ce8022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(len(docs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "927a4c65-aa05-486c-8295-2f99673e7c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split\n",
    "text_splitter = SemanticChunker(OpenAIEmbeddings())\n",
    "#text_splitter = RecursiveCharacterTextSplitter()\n",
    "splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b13568c-d633-464d-8c43-0d55f34cc8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embed\n",
    "vectorstore = Chroma.from_documents(documents=splits, \n",
    "                                    embedding=OpenAIEmbeddings())\n",
    "\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ce8df01-925b-45b5-8fb8-17b5c40c581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### RETRIEVAL and GENERATION ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eb47c817-b5ac-4d90-84ee-4cd209e52a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/workspaces/Unlocking-Data-with-GenAI-and-RAG/.venv/lib/python3.12/site-packages/langsmith/client.py:241: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Prompt - ignore LangSmith warning, you will not need langsmith for this coding exercise\n",
    "prompt = hub.pull(\"jclemens24/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8975479-b3e3-481d-ad7b-08b4eb3faaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "deb6d70c-42ef-4bda-9607-48f02c941280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM\n",
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd9db713-f705-4b65-800e-2c4e3d0e4ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain it all together with LangChain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8b30177a-f9ab-45e4-812d-33b0f97325bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"The advantages of using Retrieval-Augmented Generation (RAG) include:\\n\\n1. **Improved Accuracy and Relevance**: RAG enhances the accuracy and relevance of responses generated by large language models (LLMs) by incorporating specific, real-time information from databases or datasets.\\n\\n2. **Customization and Flexibility**: RAG allows for tailored responses based on a company's specific needs by integrating internal databases, creating personalized experiences and outputs that meet unique business requirements.\\n\\n3. **Expanding Model Knowledge Beyond Training Data**: RAG enables models to access and utilize information that was not included in their initial training sets, effectively broadening the model's knowledge base without the need for retraining.\\n\\nThese advantages make RAG a powerful tool for organizations looking to leverage their internal data and improve the effectiveness of AI applications.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Question - run the chain\n",
    "rag_chain.invoke(\"What are the advantages of using RAG?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7082f647-bf11-4dee-8121-ae8c8a66cb4b",
   "metadata": {},
   "source": [
    "\"The advantages of using Retrieval-Augmented Generation (RAG) include:\\n\\n1. **Improved Accuracy and Relevance**: RAG enhances the accuracy and relevance of responses generated by large language models (LLMs) by incorporating specific, real-time information from databases or datasets.\\n\\n2. **Customization and Flexibility**: RAG allows for tailored responses based on a company's specific needs by integrating internal databases, creating personalized experiences and outputs that meet unique business requirements.\\n\\n3. **Expanding Model Knowledge Beyond Training Data**: RAG enables models to access and utilize information that was not included in their initial training sets, effectively broadening the model's knowledge base without the need for retraining.\\n\\nThese advantages make RAG a powerful tool for organizations looking to leverage their internal data and improve the effectiveness of AI applications.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a9daeea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3341/3434088383.py:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  relevant_docs = retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://kbourne.github.io/chapter1.html'}, page_content='Can you imagine what you could do with all of the benefits mentioned above, but combined with all of the data within your company, about everything your company has ever done, about your customers and all of their interactions, or about all of your products and services combined with a knowledge of what a specific customer’s needs are? You do not have to imagine it, that is what RAG does! Even smaller companies are not able to access much of their internal data resources very effectively. Larger companies are swimming in petabytes of data that is not readily accessible or is not being fully utilized. Prior to RAG, most of the services you saw that connected customers or employees with the data resources of the company were really just scratching the surface of what is possible compared to if they could access ALL of the data in the company. With the advent of RAG and generative AI in general, corporations are on the precipice of something really, really big. Comparing RAG with Model Fine-Tuning#\\nEstablished Large Language Models (LLM), what we call the foundation models, can learn in two ways:\\n Fine-tuning - With fine-tuning, you are adjusting the weights and/or biases that define the model\\'s intelligence based on new training data. This directly impacts the model, permanently changing how it will interact with new inputs. Input/Prompts - This is where you actually \"use\" the model, using the prompt/input to introduce new knowledge that the LLM can act upon. Why not use fine-tuning in all situations?'),\n",
       " Document(metadata={'source': 'https://kbourne.github.io/chapter1.html'}, page_content='Fine-tuning, on the other hand, is more suitable for teaching the model specialized tasks or adapting it to a specific domain. Keep in mind the limitations of context window sizes and the potential for overfitting when fine-tuning on a specific dataset. '),\n",
       " Document(metadata={'source': 'https://kbourne.github.io/chapter1.html'}, page_content='Maintaining this integration over time, especially as data sources evolve or expand, adds even more complexity and cost. Organizations need to invest in technical expertise and infrastructure to effectively leverage RAG capabilities while accounting for the rapid increase in complexities these systems bring with them. Potential for Information Overload: \\nIt is very possible for RAG-based systems to pull in too much information. It is just as important to implement mechanisms to address this issue as it is to handle times when not enough relevant information is found. Determining the relevance and importance of retrieved information to be included in the final output requires sophisticated filtering and ranking mechanisms. Without these, the quality of the generated content could be compromised by an excess of unnecessary or marginally relevant details. RAG Vocabulary#\\nNow is as good a time as any to review some vocabulary that should help you get familiar with the various concepts in RAG. This is not an exhaustive list, but understanding these core concepts should help you understand everything else we teach you about RAG in a more effective way:\\nLarge Language Model (LLM)\\nMost of this book will deal with LLMs. LLMs are generative AI technologies that focus on generating text.'),\n",
       " Document(metadata={'source': 'https://kbourne.github.io/chapter1.html'}, page_content='But there are many other skills these foundation models can be fine-tuned for. LLaMA 2 is a foundation model and because it is open source, there are many spin offs that have been fine-tuned for many applications, such as medical research and conversation. Most of the models we talk about are very close to foundation models, but will likely be fine-tuned for at least conversational capabilities. Parameters and Biases\\nWe are trying to keep our focus on RAG primarily in this book, but it will be helpful for you to understand what parameters and biases are in LLM models. In machine learning models in general, including LLMs, parameters and biases are the learnable variables that the model adjusts during the training process to improve its performance on a given task. Parameters are the weights associated with the connections between neurons in the model\\'s architecture. These weights determine the strength and importance of each connection and are updated during training to minimize the difference between the model\\'s predictions and the expected outputs. Biases, on the other hand, are additional values added to the weighted sum of inputs at each neuron. They help the model learn an offset or shift in the data, allowing for more flexibility in fitting the training data. Together, parameters and biases form the learnable components of the model that are fine-tuned using the training data to improve the model\\'s performance on specific tasks or domains. Understanding parameters and biases is important in the context of RAG because the process of training and fine-tuning LLMs involves adjusting these variables. I mention foundation models, where the initial training involves setting these parameters and biases. However, fine-tuning an LLM by further adjusting its parameters and biases can significantly impact its performance and behavior within a RAG pipeline. By adapting the model to specific domains, writing styles, or tasks, you can improve the accuracy and relevance of the LLM\\'s responses when it is used to generate output based on the retrieved information. This, in turn, can lead to better overall performance of the RAG system in terms of providing more useful and context-appropriate answers to user queries. Therefore, choosing an LLM that is properly fine-tuned for your domain, or applying the fine-tuning yourself, is crucial for optimizing the most important element of your RAG pipeline. Prompting, Prompt Design, Prompt Engineering\\nThese terms are sometimes used interchangeably, but technically, while they all have to do with prompting, they do have fairly different meanings. Prompting is the act of sending a query or “prompt” into an LLM. Prompt design refers to the strategy you take to “design” the prompt you will send to the LLM. There are many different prompt design strategies that work in different scenarios, and we will review many of these in Chapter 13, Utilizing Prompt Engineering to Improve RAG Efforts. We will also review prompt engineering in chapter 13. Prompt engineering focuses more on the technical aspects surrounding the prompt that you use to improve the outputs from the LLM. For example, you may break up a complex query into two or three different LLM interactions, “engineering” it better to achieve superior results. Inference\\nWe will use the term ‘inference’ from time to time. Generally, this refers to the process of the LLM generating outputs or predictions based on given inputs using a pre-trained language model. But a key aspect of inference is that with an LLM, particularly with the cloud-based providers, you are charged based on the inference. Context Window\\nA context window, in the context of LLMs, refers to the maximum number of tokens (words, subwords, or characters) that the model can process as input or generate as output in a single pass. It determines the amount of text the model can \"see\" or \"attend to\" at once when making predictions or generating responses. The context window size is a key parameter of the model architecture and is typically fixed during model training. It directly relates to the input size of the model, as it sets an upper limit on the number of tokens that can be fed into the model at a time. For example, if a model has a context window size of 4,096 tokens, it means that the model can process and generate sequences of up to 4,096 tokens. When processing longer texts, such as documents or conversations, the input needs to be divided into smaller segments that fit within the context window. This is often done using techniques like sliding windows or truncation. The size of the context window has implications for the model\\'s ability to understand and maintain long-range dependencies and context. Models with larger context windows can capture and utilize more contextual information when generating responses, which can lead to more coherent and contextually relevant outputs. However, increasing the context window size also increases the computational resources required to train and run the model. In the context of RAG, the context window size is particularly important because it determines how much information from the retrieved documents can be effectively utilized by the model when generating the final response. Recent advancements in language models have led to the development of models with significantly larger context windows, enabling them to process and retain more information from the retrieved sources. Fine-Tuning in 2 Flavors: Full Model Fine Tuning (FMFT) and Parameter Efficient Fine Tuning (PEFT)\\nFull model fine-tuning (FMFT) is where you take a foundation model and train it further to gain new capabilities. You could simply give it new knowledge for a specific domain, or you could give it a skill, like being a conversational chat-bot. FMFT updates all of the parameters and biases in the model. PEFT is a type of fine-tuning, where you focus only on specific parts of the parameters or biases when you fine-tune the model, but with a similar goal as general fine-tuning. The latest research in this area shows that you can achieve similar results to FMFT with far less cost, time commitment, and data. While this book is not focused on fine-tuning, it is a very valid strategy to try to use a model fine-tuned with your own data to give it more knowledge from your domain or to give it more of “voice” from your domain. For example, you could train it to talk more like a scientist than a generic foundation model, if using this in a scientific field.')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How does RAG compare with fine-tuning?\"\n",
    "relevant_docs = retriever.get_relevant_documents(query)\n",
    "relevant_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "942bffcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://kbourne.github.io/chapter1.html'}, page_content='Once you have introduced the new knowledge, it will always have it! It is also how the model was originally created, by training with data, right? That sounds right in theory, but in practice, fine-tuning has been more reliable in teaching a model specialized tasks (like teaching a model how to converse in a certain way), and less reliable for factual recall. The reason is complicated, but in general, a model’s knowledge of facts is like a human’s long-term memory. If you memorize a long passage from a speech or book and then try to recall it a few months later, you will likely still understand the context of the information, but you may forget specific details. Whereas, adding knowledge through the input of the model is like our short-term memory, where the facts, details, and even the order of wording is all very fresh and available for recall. It is this latter scenario that lends itself better in a situation where you want successful factual recall. There is a trade-off though. Inputs are limited by the context window of the model. This is an area that is actively being addressed though. For example, ChatGPT 3.5 only had a 4,096 token context window, which is the equivalent of about 5 pages of text. When ChatGPT 4 was released, they expanded the context window to 8,192 tokens (10 pages) and there was a Chat 4-32k version that had a context window of 32,768 tokens  (40 pages). This issue is so important that they included the context window size in the name of the model.'),\n",
       " Document(metadata={'source': 'https://kbourne.github.io/chapter1.html'}, page_content='Or if you are developing in a legal field, you may want it to sound more like a lawyer. Vector Store or Vector Database?'),\n",
       " Document(metadata={'source': 'https://kbourne.github.io/chapter1.html'}, page_content='That is a strong indicator of how important the context window is! What about the latest Gemini 1.5 model? 1M token context window, or over 1,000 pages. As the context windows expand though, this has created another issue. Early models with expanded context windows were shown to lose a lot of the details, especially in the “middle” of the text. This issue is also being addressed. The Gemini 1.5 model with the 1 million token context window has performed well in tests called “needle-in-a-haystack” tests for “remembering” all details well throughout the text it can take as input. Unfortunately, the model did not perform as well in the “multiple needle’s in a haystack” tests. Anthropic’s largest version of their latest model, Claude 3 Opus, performs fairly well with contest windows of 200,000 words. Expect more effort in this area as these context windows get larger, and keep this in mind if you need to work with large amounts of text at a time.'),\n",
       " Document(metadata={'source': 'https://kbourne.github.io/chapter1.html'}, page_content=\"NOTE: It is important to note that token count differs from word count, as tokens include punctuation, symbols, numbers, and other text representations. How a compound word like “ice cream” is treated token-wise depends on the tokenization scheme and it can vary across LLM. But most well-known LLMs (like ChatGPT and Gemini) would be considered 2 tokens. Under certain circumstances in NLP you may argue that it should be one based on the concept that a token should represent a useful semantic unit for processing. Ultimately, when deciding between RAG and fine-tuning, consider your specific use case and requirements. RAG is generally superior for retrieving factual information that is not present in the LLM's training data or is private. It allows for dynamic integration of external knowledge without modifying the model's weights.\")]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"How many hours school bus drivers work during the week in Washington state?\"\n",
    "relevant_docs = retriever.get_relevant_documents(query)\n",
    "relevant_docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
